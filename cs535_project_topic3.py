# -*- coding: utf-8 -*-
"""DataMiningProject_Topic3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1COv-WR5iEp1RsVX32MxXAp1axJUJdjP6

# **DATA MINING PROJECT TOPIC 3**
# **Group Number:- 27**
# **TEAMMATES:**
# **Kaushal Thakar**
# **Sathwik Krishtipati**
# **Vikas Kiran Nadikuda**
# **KishoreKumar Basam**
# **Teresa Chu**

# **PROBLEM 1- DENSITY ESTIMATION USING REALNVP**

## Reference Code(from the github link provided in the document to use as library: https://github.com/chrischute/real-nvp). Issues with cloning, so code is directly included the code block down below. As stated in the paper, code 1 provided is used as a library for the following problems
"""

import torch
from torch import nn, optim, distributions
from torch.nn import functional as F
from torchvision import transforms
from torchvision.utils import save_image

from sklearn import datasets
import numpy as np
import matplotlib.pyplot as plt
from pylab import rcParams
import os

#config#
BATCH_SIZE = 128
time_interval = 50
EPOCHS = 5 #epoch can be changed if need more accurate results
in_dimensions = 2
out_dimensions = 2
hid_dimensions = 256
save_interval = 5
co_layers = 8

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

rcParams['figure.figsize'] = 8, 8
plt.ion()


# main data loaders(FOR CIRCLE USE(make_circles)and for BLOBS USE(make_blobs)) #
train_data = datasets.make_moons(n_samples=50000, noise=.05)[0].astype(np.float32) # make_circles and make_blobs for circle and blob density estimation
test_data = datasets.make_moons(n_samples=1000, noise=.05)[0].astype(np.float32)   # make_circles and make_blobs for circle and blob density estimation


kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}
train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, **kwargs)



class CouplingLayer(nn.Module):
    def __init__(self, in_dimensions, out_dimensions, hid_dim, layer):
        super().__init__()
        self.sf_c1 = nn.Linear(in_dimensions, hid_dim)
        self.sf_c2 = nn.Linear(hid_dim, hid_dim)
        self.sf_c3 = nn.Linear(hid_dim, out_dimensions)
        self.tf_c1 = nn.Linear(in_dimensions, hid_dim)
        self.tf_c2 = nn.Linear(hid_dim, hid_dim)
        self.t_fc3 = nn.Linear(hid_dim, out_dimensions)
        self.layer = layer

    def forward(self, x):
        x_m = x * self.layer
        s_out = torch.tanh(self.sf_c3(F.relu(self.sf_c2(F.relu(self.sf_c1(x_m))))))
        t_out = self.t_fc3(F.relu(self.tf_c2(F.relu(self.tf_c1(x_m)))))
        y = x_m + (1-self.layer)*(x*torch.exp(s_out)+t_out)
        log_det_jacobian = s_out.sum(dim=1)
        return y, log_det_jacobian

    def backward(self, y):
        y_m = y * self.layer
        s_out = torch.tanh(self.sf_c3(F.relu(self.sf_c2(F.relu(self.sf_c1(y_m))))))
        t_out = self.t_fc3(F.relu(self.tf_c2(F.relu(self.tf_c1(y_m)))))
        x = y_m + (1-self.layer)*(y-t_out)*torch.exp(-s_out)
        return x


class RealNVP(nn.Module):
    def __init__(self, in_dimensions, out_dimensions, hid_dim, layer, n_layers = 6):
        super().__init__()
        assert n_layers >= 2, 'num of coupling layers should be greater or equal to 2'

        self.modules = []
        self.modules.append(CouplingLayer(in_dimensions, out_dimensions, hid_dim, layer))
        for _ in range(n_layers-2):
            layer = 1 - layer
            self.modules.append(CouplingLayer(in_dimensions, out_dimensions, hid_dim, layer))
        self.modules.append(CouplingLayer(in_dimensions, out_dimensions, hid_dim, 1 - layer))
        self.module_list = nn.ModuleList(self.modules)
        
    def forward(self, x):
        ldj_sum = 0 # jacobian calculation is performed
        for module in self.module_list:
            x, ldj= module(x)
            ldj_sum += ldj
        return x, ldj_sum

    def backward(self, z):
        for module in reversed(self.module_list):
            z = module.backward(z)
        return z


layer = torch.from_numpy(np.array([0, 1]).astype(np.float32))
model = RealNVP(in_dimensions, out_dimensions, hid_dimensions, layer, co_layers)
opt = torch.optim.Adam(model.parameters(), lr=1e-4)
old_z = distributions.MultivariateNormal(torch.zeros(2), torch.eye(2))


# train and testing for the density estimation #
def train(epoch):
    model.train()
    train_loss = 0
    for batch_idx, data in enumerate(train_loader):
        opt.zero_grad()
        z, main_sum = model(data)
        loss = -(old_z.log_prob(z)+main_sum).mean()
        loss.backward()
        cur_loss = loss.item()
        train_loss += cur_loss
        opt.step()
        if batch_idx % time_interval == 0:
            print('Trained Epoch: {} [{}/{} ({:.0f}%)]\tLossin%: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100.*batch_idx / len(train_loader),
                cur_loss/len(data)))

    print('====> Epoch: {} Average loss: {:.4f}'.format(
        epoch, train_loss / len(train_loader.dataset)
    ))


def test(epoch):
    model.eval()
    test_loss = 0
    x_all = np.array([[]]).reshape(0,2)
    z_all = np.array([[]]).reshape(0,2)
    with torch.no_grad():
        for batch_idx, data in enumerate(test_loader):
            z, main_sum = model(data)
            cur_loss = -(old_z.log_prob(z)+main_sum).mean().item()
            test_loss += cur_loss
            x_all = np.concatenate((x_all,data.numpy()))
            z_all = np.concatenate((z_all,z.numpy()))
        
        subfig_plot(1, x_all, -2, 3, -1, 1.5,'Input: x ~ p(x)', 'b')
        subfig_plot(2, z_all, -3, 3, -3,3,'Output: z = f(x)', 'b')

        test_loss /= len(test_loader.dataset)
        print('====> Test set loss: {:.4f}'.format(test_loss))


#function#
def sample(epoch):
    model.eval()
    with torch.no_grad():
        z = old_z.sample((1000,))
        x = model.backward(z)
        z = z.numpy()
        x = x.numpy()

        subfig_plot(3, z, -3, 3, -3, 3, 'Input: z ~ p(z)', 'r')
        subfig_plot(4, x, -2, 3, -1, 1.5,'Output: x = g(z) (g: inverse of f)', 'r')

        if epoch % save_interval == 0:
            if not os.path.exists('results'):
                os.makedirs('results')
            plt.savefig('results/'+'result_'+str(epoch)+'.png')


def subfig_plot(location, data, x_start, x_end, y_start, y_end, title, color):
        if location == 1:
            plt.clf()
        plt.subplot(2,2,location)
        plt.scatter(data[:, 0], data[:, 1], c=color, s=1)
        plt.xlim(x_start,x_end)
        plt.ylim(y_start,y_end)
        plt.title(title)
        plt.pause(1e-2)



if __name__ == '__main__':
    for epoch in range(1, EPOCHS + 1):
        train(epoch)
        test(epoch)
        sample(epoch)

"""#  USING REALNVP FOR PROBLEM 3-6 with github code as library as mentioned abvoe

# Problem 3: Use Real NVP to do classification on MNIST dataset. Report the prediction accuracy. #Accuracy-78.28
"""

# !git clone https://github.com/chrischute/real-nvp.git rnvp

# %cd /content/rnvp

import numpy as np
import torch.nn as nn

import torch
import torch.nn.functional as F


def squeeze_2x2(x, reverse=False, alt_order=False):
    """For each spatial position, a sub-volume of shape `1x1x(N^2 * C)`,
    reshape into a sub-volume of shape `NxNxC`, where `N = block_size`.

    Adapted from:
        https://github.com/tensorflow/models/blob/master/research/real_nvp/real_nvp_utils.py

    See Also:
        - TensorFlow nn.depth_to_space: https://www.tensorflow.org/api_docs/python/tf/nn/depth_to_space
        - Figure 3 of RealNVP paper: https://arxiv.org/abs/1605.08803

    Args:
        x (torch.Tensor): Input tensor of shape (B, C, H, W).
        reverse (bool): Whether to do a reverse squeeze (unsqueeze).
        alt_order (bool): Whether to use alternate ordering.
    """
    block_size = 2
    if alt_order:
        n, c, h, w = x.size()

        if reverse:
            if c % 4 != 0:
                raise ValueError('Number of channels must be divisible by 4, got {}.'.format(c))
            c //= 4
        else:
            if h % 2 != 0:
                raise ValueError('Height must be divisible by 2, got {}.'.format(h))
            if w % 2 != 0:
                raise ValueError('Width must be divisible by 4, got {}.'.format(w))
        # Defines permutation of input channels (shape is (4, 1, 2, 2)).
        squeeze_matrix = torch.tensor([[[[1., 0.], [0., 0.]]],
                                       [[[0., 0.], [0., 1.]]],
                                       [[[0., 1.], [0., 0.]]],
                                       [[[0., 0.], [1., 0.]]]],
                                      dtype=x.dtype,
                                      device=x.device)
        perm_weight = torch.zeros((4 * c, c, 2, 2), dtype=x.dtype, device=x.device)
        for c_idx in range(c):
            slice_0 = slice(c_idx * 4, (c_idx + 1) * 4)
            slice_1 = slice(c_idx, c_idx + 1)
            perm_weight[slice_0, slice_1, :, :] = squeeze_matrix
        shuffle_channels = torch.tensor([c_idx * 4 for c_idx in range(c)]
                                        + [c_idx * 4 + 1 for c_idx in range(c)]
                                        + [c_idx * 4 + 2 for c_idx in range(c)]
                                        + [c_idx * 4 + 3 for c_idx in range(c)])
        perm_weight = perm_weight[shuffle_channels, :, :, :]

        if reverse:
            x = F.conv_transpose2d(x, perm_weight, stride=2)
        else:
            x = F.conv2d(x, perm_weight, stride=2)
    else:
        b, c, h, w = x.size()
        x = x.permute(0, 2, 3, 1)

        if reverse:
            if c % 4 != 0:
                raise ValueError('Number of channels {} is not divisible by 4'.format(c))
            x = x.view(b, h, w, c // 4, 2, 2)
            x = x.permute(0, 1, 4, 2, 5, 3)
            x = x.contiguous().view(b, 2 * h, 2 * w, c // 4)
        else:
            if h % 2 != 0 or w % 2 != 0:
                raise ValueError('Expected even spatial dims HxW, got {}x{}'.format(h, w))
            x = x.view(b, h // 2, 2, w // 2, 2, c)
            x = x.permute(0, 1, 3, 5, 2, 4)
            x = x.contiguous().view(b, h // 2, w // 2, c * 4)

        x = x.permute(0, 3, 1, 2)

    return x


def checkerboard_mask(height, width, reverse=False, dtype=torch.float32,
                      device=None, requires_grad=False):
    """Get a checkerboard mask, such that no two entries adjacent entries
    have the same value. In non-reversed mask, top-left entry is 0.

    Args:
        height (int): Number of rows in the mask.
        width (int): Number of columns in the mask.
        reverse (bool): If True, reverse the mask (i.e., make top-left entry 1).
            Useful for alternating masks in RealNVP.
        dtype (torch.dtype): Data type of the tensor.
        device (torch.device): Device on which to construct the tensor.
        requires_grad (bool): Whether the tensor requires gradient.


    Returns:
        mask (torch.tensor): Checkerboard mask of shape (1, 1, height, width).
    """
    checkerboard = [[((i % 2) + j) % 2 for j in range(width)] for i in range(height)]
    mask = torch.tensor(checkerboard, dtype=dtype, device=device, requires_grad=requires_grad)

    if reverse:
        mask = 1 - mask

    # Reshape to (1, 1, height, width) for broadcasting with tensors of shape (B, C, H, W)
    mask = mask.view(1, 1, height, width)

    return mask

class RealNVPLoss(nn.Module):
    """Get the NLL loss for a RealNVP model.

    Args:
        k (int or float): Number of discrete values in each input dimension.
            E.g., `k` is 256 for natural images.

    See Also:
        Equation (3) in the RealNVP paper: https://arxiv.org/abs/1605.08803
    """
    def __init__(self, k=256):
        super(RealNVPLoss, self).__init__()
        self.k = k

    def forward(self, z, sldj):
        prior_ll = -0.5 * (z ** 2 + np.log(2 * np.pi))
        prior_ll = prior_ll.contiguous().view(z.size(0), -1).sum(-1) \
            - np.log(self.k) * np.prod(z.size()[1:])
        ll = prior_ll + sldj
        nll = -ll.mean()

        return nll

import torch
import torch.nn as nn

from enum import IntEnum
# from models.resnet import ResNet
# from util import checkerboard_mask


class MaskType(IntEnum):
    CHECKERBOARD = 0
    CHANNEL_WISE = 1


class CouplingLayer(nn.Module):
    """Coupling layer in RealNVP.

    Args:
        in_channels (int): Number of channels in the input.
        mid_channels (int): Number of channels in the `s` and `t` network.
        num_blocks (int): Number of residual blocks in the `s` and `t` network.
        mask_type (MaskType): One of `MaskType.CHECKERBOARD` or `MaskType.CHANNEL_WISE`.
        reverse_mask (bool): Whether to reverse the mask. Useful for alternating masks.
    """
    def __init__(self, in_channels, mid_channels, num_blocks, mask_type, reverse_mask):
        super(CouplingLayer, self).__init__()

        # Save mask info
        self.mask_type = mask_type
        self.reverse_mask = reverse_mask

        # Build scale and translate network
        if self.mask_type == MaskType.CHANNEL_WISE:
            in_channels //= 2
        self.st_net = ResNet(in_channels, mid_channels, 2 * in_channels,
                             num_blocks=num_blocks, kernel_size=3, padding=1,
                             double_after_norm=(self.mask_type == MaskType.CHECKERBOARD))

        # Learnable scale for s
        self.rescale = nn.utils.weight_norm(Rescale(in_channels))

    def forward(self, x, sldj=None, reverse=True):
        if self.mask_type == MaskType.CHECKERBOARD:
            # Checkerboard mask
            b = checkerboard_mask(x.size(2), x.size(3), self.reverse_mask, device=x.device)
            x_b = x * b
            st = self.st_net(x_b)
            s, t = st.chunk(2, dim=1)
            s = self.rescale(torch.tanh(s))
            s = s * (1 - b)
            t = t * (1 - b)

            # Scale and translate
            if reverse:
                inv_exp_s = s.mul(-1).exp()
                if torch.isnan(inv_exp_s).any():
                    raise RuntimeError('Scale factor has NaN entries')
                x = x * inv_exp_s - t
            else:
                exp_s = s.exp()
                if torch.isnan(exp_s).any():
                    raise RuntimeError('Scale factor has NaN entries')
                x = (x + t) * exp_s

                # Add log-determinant of the Jacobian
                sldj += s.contiguous().view(s.size(0), -1).sum(-1)
        else:
            # Channel-wise mask
            if self.reverse_mask:
                x_id, x_change = x.chunk(2, dim=1)
            else:
                x_change, x_id = x.chunk(2, dim=1)

            st = self.st_net(x_id)
            s, t = st.chunk(2, dim=1)
            s = self.rescale(torch.tanh(s))

            # Scale and translate
            if reverse:
                inv_exp_s = s.mul(-1).exp()
                if torch.isnan(inv_exp_s).any():
                    raise RuntimeError('Scale factor has NaN entries')
                x_change = x_change * inv_exp_s - t
            else:
                exp_s = s.exp()
                if torch.isnan(exp_s).any():
                    raise RuntimeError('Scale factor has NaN entries')
                x_change = (x_change + t) * exp_s

                # Add log-determinant of the Jacobian
                sldj += s.contiguous().view(s.size(0), -1).sum(-1)

            if self.reverse_mask:
                x = torch.cat((x_id, x_change), dim=1)
            else:
                x = torch.cat((x_change, x_id), dim=1)

        return x, sldj

class WNConv2d(nn.Module):
    """Weight-normalized 2d convolution.

    Args:
        in_channels (int): Number of channels in the input.
        out_channels (int): Number of channels in the output.
        kernel_size (int): Side length of each convolutional kernel.
        padding (int): Padding to add on edges of input.
        bias (bool): Use bias in the convolution operation.
    """
    def __init__(self, in_channels, out_channels, kernel_size, padding, bias=True):
        super(WNConv2d, self).__init__()
        self.conv = nn.utils.weight_norm(
            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=bias))

    def forward(self, x):
        x = self.conv(x)

        return x

class Rescale(nn.Module):
    """Per-channel rescaling. Need a proper `nn.Module` so we can wrap it
    with `torch.nn.utils.weight_norm`.

    Args:
        num_channels (int): Number of channels in the input.
    """
    def __init__(self, num_channels):
        super(Rescale, self).__init__()
        self.weight = nn.Parameter(torch.ones(num_channels, 1, 1))

    def forward(self, x):
        x = self.weight * x
        return x


import torch
import torch.nn as nn
import torch.nn.functional as F

# from models.resnet.residual_block import ResidualBlock
# from util import WNConv2d


class ResNet(nn.Module):
    """ResNet for scale and translate factors in Real NVP.

    Args:
        in_channels (int): Number of channels in the input.
        mid_channels (int): Number of channels in the intermediate layers.
        out_channels (int): Number of channels in the output.
        num_blocks (int): Number of residual blocks in the network.
        kernel_size (int): Side length of each filter in convolutional layers.
        padding (int): Padding for convolutional layers.
        double_after_norm (bool): Double input after input BatchNorm.
    """
    def __init__(self, in_channels, mid_channels, out_channels,
                 num_blocks, kernel_size, padding, double_after_norm):
        super(ResNet, self).__init__()
        self.in_norm = nn.BatchNorm2d(in_channels)
        self.double_after_norm = double_after_norm
        self.in_conv = WNConv2d(2 * in_channels, mid_channels, kernel_size, padding, bias=True)
        self.in_skip = WNConv2d(mid_channels, mid_channels, kernel_size=1, padding=0, bias=True)

        self.blocks = nn.ModuleList([ResidualBlock(mid_channels, mid_channels)
                                     for _ in range(num_blocks)])
        self.skips = nn.ModuleList([WNConv2d(mid_channels, mid_channels, kernel_size=1, padding=0, bias=True)
                                    for _ in range(num_blocks)])

        self.out_norm = nn.BatchNorm2d(mid_channels)
        self.out_conv = WNConv2d(mid_channels, out_channels, kernel_size=1, padding=0, bias=True)

    def forward(self, x):
        x = self.in_norm(x)
        if self.double_after_norm:
            x *= 2.
        x = torch.cat((x, -x), dim=1)
        x = F.relu(x)
        x = self.in_conv(x)
        x_skip = self.in_skip(x)

        for block, skip in zip(self.blocks, self.skips):
            x = block(x)
            x_skip += skip(x)

        x = self.out_norm(x_skip)
        x = F.relu(x)
        x = self.out_conv(x)

        return x

import torch.nn as nn
import torch.nn.functional as F

# from util import WNConv2d


class ResidualBlock(nn.Module):
    """ResNet basic block with weight norm."""
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()

        self.in_norm = nn.BatchNorm2d(in_channels)
        self.in_conv = WNConv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)

        self.out_norm = nn.BatchNorm2d(out_channels)
        self.out_conv = WNConv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True)

    def forward(self, x):
        skip = x

        x = self.in_norm(x)
        x = F.relu(x)
        x = self.in_conv(x)

        x = self.out_norm(x)
        x = F.relu(x)
        x = self.out_conv(x)

        x = x + skip

        return x


import torch
import torch.nn as nn
import torch.nn.functional as F

# from models.real_nvp.coupling_layer import CouplingLayer, MaskType
# from util import squeeze_2x2


class RealNVP(nn.Module):
    """RealNVP Model

    Based on the paper:
    "Density estimation using Real NVP"
    by Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio
    (https://arxiv.org/abs/1605.08803).

    Args:
        num_scales (int): Number of scales in the RealNVP model.
        in_channels (int): Number of channels in the input.
        mid_channels (int): Number of channels in the intermediate layers.
        num_blocks (int): Number of residual blocks in the s and t network of
        `Coupling` layers.
    """
    def __init__(self, num_scales=2, in_channels=3, mid_channels=64, num_blocks=8):
        super(RealNVP, self).__init__()
        # Register data_constraint to pre-process images, not learnable
        self.register_buffer('data_constraint', torch.tensor([0.9], dtype=torch.float32))

        self.flows = _RealNVP(0, num_scales, in_channels, mid_channels, num_blocks)

    def forward(self, x, reverse=False):
        sldj = None
        if not reverse:
            # Expect inputs in [0, 1]
            if x.min() < 0 or x.max() > 1:
                raise ValueError('Expected x in [0, 1], got x with min/max {}/{}'
                                 .format(x.min(), x.max()))

            # De-quantize and convert to logits
            x, sldj = self._pre_process(x)

        x, sldj = self.flows(x, sldj, reverse)

        return x, sldj

    def _pre_process(self, x):
        """Dequantize the input image `x` and convert to logits.

        Args:
            x (torch.Tensor): Input image.

        Returns:
            y (torch.Tensor): Dequantized logits of `x`.

        See Also:
            - Dequantization: https://arxiv.org/abs/1511.01844, Section 3.1
            - Modeling logits: https://arxiv.org/abs/1605.08803, Section 4.1
        """
        y = (x * 255. + torch.rand_like(x)) / 256.
        y = (2 * y - 1) * self.data_constraint
        y = (y + 1) / 2
        y = y.log() - (1. - y).log()

        # Save log-determinant of Jacobian of initial transform
        ldj = F.softplus(y) + F.softplus(-y) \
            - F.softplus((1. - self.data_constraint).log() - self.data_constraint.log())
        sldj = ldj.view(ldj.size(0), -1).sum(-1)

        return y, sldj


class _RealNVP(nn.Module):
    """Recursive builder for a `RealNVP` model.

    Each `_RealNVPBuilder` corresponds to a single scale in `RealNVP`,
    and the constructor is recursively called to build a full `RealNVP` model.

    Args:
        scale_idx (int): Index of current scale.
        num_scales (int): Number of scales in the RealNVP model.
        in_channels (int): Number of channels in the input.
        mid_channels (int): Number of channels in the intermediate layers.
        num_blocks (int): Number of residual blocks in the s and t network of
            `Coupling` layers.
    """
    def __init__(self, scale_idx, num_scales, in_channels, mid_channels, num_blocks):
        super(_RealNVP, self).__init__()

        self.is_last_block = scale_idx == num_scales - 1

        self.in_couplings = nn.ModuleList([
            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=False),
            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=True),
            CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=False)
        ])

        if self.is_last_block:
            self.in_couplings.append(
                CouplingLayer(in_channels, mid_channels, num_blocks, MaskType.CHECKERBOARD, reverse_mask=True))
        else:
            self.out_couplings = nn.ModuleList([
                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=False),
                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=True),
                CouplingLayer(4 * in_channels, 2 * mid_channels, num_blocks, MaskType.CHANNEL_WISE, reverse_mask=False)
            ])
            self.next_block = _RealNVP(scale_idx + 1, num_scales, 2 * in_channels, 2 * mid_channels, num_blocks)

    def forward(self, x, sldj, reverse=False):
        if reverse:
            if not self.is_last_block:
                # Re-squeeze -> split -> next block
                x = squeeze_2x2(x, reverse=False, alt_order=True)
                x, x_split = x.chunk(2, dim=1)
                x, sldj = self.next_block(x, sldj, reverse)
                x = torch.cat((x, x_split), dim=1)
                x = squeeze_2x2(x, reverse=True, alt_order=True)

                # Squeeze -> 3x coupling (channel-wise)
                x = squeeze_2x2(x, reverse=False)
                for coupling in reversed(self.out_couplings):
                    x, sldj = coupling(x, sldj, reverse)
                x = squeeze_2x2(x, reverse=True)

            for coupling in reversed(self.in_couplings):
                x, sldj = coupling(x, sldj, reverse)
        else:
            for coupling in self.in_couplings:
                x, sldj = coupling(x, sldj, reverse)

            if not self.is_last_block:
                # Squeeze -> 3x coupling (channel-wise)
                x = squeeze_2x2(x, reverse=False)
                for coupling in self.out_couplings:
                    x, sldj = coupling(x, sldj, reverse)
                x = squeeze_2x2(x, reverse=True)

                # Re-squeeze -> split -> next block
                x = squeeze_2x2(x, reverse=False, alt_order=True)
                x, x_split = x.chunk(2, dim=1)
                x, sldj = self.next_block(x, sldj, reverse)
                x = torch.cat((x, x_split), dim=1)
                x = squeeze_2x2(x, reverse=True, alt_order=True)

        return x, sldj

import torch
from torch import nn
import numpy as np
from torchvision import datasets, transforms
import itertools
import matplotlib.pyplot as plt
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

class classification_model_cifar10(nn.Module):
  def __init__(self, classes, channel):
    super().__init__()
    self.cnn_e1 = nn.Conv2d(channel,32, stride=2, kernel_size=3, padding=1)
    self.cnn_e2 = nn.Conv2d(32, 32, stride=2, kernel_size=3, padding=1)
    self.linear_e_layer = nn.Linear(32*32*2, classes)

  def forward(self,x):

    x = self.cnn_e1(x)
    x = torch.relu(x)

    x = self.cnn_e2(x)
    x = torch.relu(x)

    x = torch.flatten(x, 1)
    x = torch.relu(x)

    x = self.linear_e_layer(x)

    return x

class classification_model_mnist(nn.Module):
  def __init__(self, classes, channel):
    super().__init__()
    self.cnn_e1 = nn.Conv2d(channel,32, stride=2, kernel_size=3, padding=1)
    self.cnn_e2 = nn.Conv2d(32, 32, stride=2, kernel_size=3, padding=1)
    self.linear_e_layer = nn.Linear(1568, classes)

  def forward(self,x):

    x = self.cnn_e1(x)
    x = torch.relu(x)

    x = self.cnn_e2(x)
    x = torch.relu(x)

    x = torch.flatten(x, 1)
    x = torch.relu(x)

    x = self.linear_e_layer(x)

    return x

import tqdm
def train(cl_model,RealNVP_model,train_loader,epochs ):
  loss_fn = RealNVPLoss()
  optimizer = torch.optim.Adam(RealNVP_model.parameters(),lr=1e-3)
  RealNVP_model.train()
  for i in range(epochs):
    print('Epoch: ',i)
    for batch_idx, data in enumerate(train_loader):

      real, labels = data
      real = real.to(device)
      rnvp_return_x, rnvp_return_y = RealNVP_model(real, reverse=False)
      loss = loss_fn(rnvp_return_x, rnvp_return_y)

      cl_model.zero_grad()  
      loss.backward()
      optimizer.step()
    print('RealNVP loss: ',loss.item())

  cl_model.train()
  RealNVP_model.eval()
  loss_fn = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(cl_model.parameters(),lr=1e-3)
  print('Training classification module...')
  for i in range(epochs):
    for data in train_loader:

      real, labels = data
      # labels  = labels.to(device)
      real = real.to(device)
      # RealNVP Images to train classifier
      rnvp_return_x, rnvp_return_y = RealNVP_model(real, reverse=False)

      pred = cl_model(rnvp_return_x)
      pred = torch.sigmoid(pred)
      pred = pred.to('cpu')
      loss = loss_fn(pred,labels)

      cl_model.zero_grad()
      loss.backward()
      optimizer.step()
    print('Classification loss:',loss.item())

def evaluation(cl_model,RealNVP_model,data_loader,classes_to_extract):
  cl_model.eval()
  RealNVP_model.eval()
  correct = 0

  classes_extraction_dict = {}
  for i in classes_to_extract:
    classes_extraction_dict[i] = []
  
  for batch_idx, data in enumerate(data_loader):
    generate = True

    real, labels = data
    
    real = real.to(device)
    # RealNVP images to train the classifier here
    rnvp_return_x, rnvp_return_y = RealNVP_model(real, reverse=False)

    pred = cl_model(rnvp_return_x)
    pred = torch.sigmoid(pred)

    pred_class = torch.argmax(pred,axis = 1)

    for i, (pred_label, real_label) in enumerate(zip(pred_class,labels)):
      if int(real_label) in classes_to_extract:

        if len(classes_extraction_dict[int(real_label)])<=5:
          if generate:
            rnvp_return_x, rnvp_return_y = RealNVP_model(real, reverse=True)
            rnvp_return_x = torch.sigmoid(rnvp_return_x)
            generate = False
          classes_extraction_dict[int(real_label)].append(rnvp_return_x[i])
      # print(pred_label, real_label) #test
      if pred_label == real_label:
        correct = correct+1
    if batch_idx == 10:
      break
  print('Classifiaction accuracy:',(correct/(batch_idx*64))*100)
  return classes_extraction_dict

data_set = datasets.MNIST('data', train=False, download=True,
                       transform=transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()]))
data_loader = torch.utils.data.DataLoader(data_set, 64)
channels = 1

RealNVP_model = RealNVP(in_channels=channels)
RealNVP_model = RealNVP_model.to(device)

cl_model = classification_model_mnist(10, channels)
cl_model = cl_model.to(device)

# training epoch 0 took 3hours
train(cl_model,RealNVP_model,data_loader,1)

# only 1 epoch was performed which took 17gb of ram(crashes on normal colab)
classes_extraction_dict = evaluation(cl_model,RealNVP_model,data_loader,
                                     [2,9])

"""# Problem 4: Interpolate the latent space to generate pictures between “2” and “9”."""

# if epoch increased results would be more clear
import matplotlib.pyplot as plt
keys = list(classes_extraction_dict.keys())
images = classes_extraction_dict[keys[0]]
for i in range(5):
  plt.subplot(2,5,i+1)
  plt.imshow(images[i].permute(1, 2, 0).cpu().detach()[:,:,0])
  plt.axis('off')

images = classes_extraction_dict[keys[1]]
for i in range(5,10):
    plt.subplot(2,5,i+1)
    plt.axis('off')
    plt.imshow(images[i-5].permute(1, 2, 0).cpu().detach()[:,:,0])

"""# Problem 5: Use Real NVP to do classification on CIFAR10 dataset. Report the prediction accuracy. #ACCURACY-39.06"""

data_set = datasets.CIFAR10('data', train=False, download=True,
                       transform=transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()]))
data_loader = torch.utils.data.DataLoader(data_set, 64)
channels = 3

RealNVP_model = RealNVP(in_channels=channels)
RealNVP_model = RealNVP_model.to(device)

cl_model = classification_model_cifar10(10, channels)
cl_model = cl_model.to(device)

train(cl_model,RealNVP_model,data_loader,1)

classes_extraction_dict = evaluation(cl_model,RealNVP_model,data_loader,
                                     [3,5])

"""# Problem 6: Interpolate the latent space to generate pictures between “cat” and “dog”."""

import matplotlib.pyplot as plt
keys = list(classes_extraction_dict.keys())
images = classes_extraction_dict[keys[0]]
for i in range(5):
  plt.subplot(2,5,i+1)
  plt.imshow(images[i].permute(1, 2, 0).cpu().detach()[:,:,0])
  plt.axis('off')

images = classes_extraction_dict[keys[1]]
for i in range(5,10):
    plt.subplot(2,5,i+1)
    plt.axis('off')
    plt.imshow(images[i-5].permute(1, 2, 0).cpu().detach()[:,:,0])